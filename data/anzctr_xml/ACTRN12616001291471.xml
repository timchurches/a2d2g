<?xml-stylesheet type='text/xsl' href='anzctrTransform.xsl'?>
<ANZCTR_Trial requestNumber="371270">
  <stage>Registered</stage>
  <submitdate>5/09/2016</submitdate>
  <approvaldate>14/09/2016</approvaldate>
  <actrnumber>ACTRN12616001291471</actrnumber>
  <trial_identification>
    <studytitle>Computer Games and Biofeedback: Can it help adults on the Autism spectrum to improve emotion recognition skills? </studytitle>
    <scientifictitle>Evaluation of a Computer-based Emotion Recognition Intervention among Individuals on the Autism Spectrum</scientifictitle>
    <utrn />
    <trialacronym />
    <secondaryid>Nil known</secondaryid>
  </trial_identification>
  <conditions>
    <healthcondition>Autism Spectrum Disorders</healthcondition>
    <healthcondition>Emotion recognition skills</healthcondition>
    <conditioncode>
      <conditioncode1>Mental Health</conditioncode1>
      <conditioncode2>Autistic spectrum disorders</conditioncode2>
    </conditioncode>
  </conditions>
  <interventions>
    <interventions>Brief name: Computer game and biofeedback (brain-computer interface)
Description of intervention: 
1. Computer game: The emotion recognition computer game will be set in a space craft setting. Participants will be playing as a robot embedded with an artificial intelligence computer chip, called C.H.I.P. The participants will be interacting with different characters in the space craft to interpret and understand emotions, with assistance from C.H.I.P who will provide clues on various emotion recognition skills.
2. Biofeedback: Eye tracking and EEG feedback will be provided to participants in the form of points. Participants will be allocated additional points for spending a specified amount of time on the core facial regions (such as the eyes, as measured by fixations) and additional points will be allocated if participants display a level of brain activity (such as theta) that meets or exceeds a predefined threshold for a given percentage of the trial. Biofeedback parameters will be defined following pilot testing. 

Materials: (1) Electroencephalogram (EEG) (2) Remote eye tracker (3) Emotion recognition Computer Game- controlled via Unity 3D. 
Procedures: After providing instructions on the set-up of the EEG, The participants head will then be measured and fitted with an EEG cap. Each of the electrodes on the EEG cap will be filled with gel to ensure conductivity between the scalp and the electrode. A few electrodes will be placed on the ears and face as EEG reference points. Before starting the computer game, participants will undergo a 9-point eye tracking calibration procedure. Following to this, the computer game will initiate and participants will receive feedback on their performance throughout the game. 
Who will deliver the intervention: Postgraduate students with a background in research and occupational therapy. 
Mode of delivery: Face to face
Duration and intensity of intervention: All participants will receive approximately 6x 1 hour sessions, once per week for six weeks. 
Location: The intervention will be held in a facility in Curtin University, Bentley, Western Australia. 
Adherence: Prior to the trial, the researcher will provide the participants with information on the intervention. Participants will be encouraged to discuss the study with someone whom they are comfortable with. During the first meeting, the researchers will provide further explanations on what the study involves (with visual instructions, if necessary). These explanations can include demonstrations of the equipment which will be used in the study. The researchers will be closely monitoring the comfort of the participants throughout the intervention and will provide breaks, if required. The presence of side effects will be monitored with a side-effects questionnaire. If the participant informs the research of any side effects, the sessions will be stopped. 
</interventions>
    <comparator>Brief name: Computer Game without biofeedback
Goal: To measure the impact of biofeedback in improving emotion recognition skills
Materials and Procedure: Participants in the active control group will undergo the same procedure as the intervention group (computer game and biofeedback) for 6 weeks (one hour per week), Participants will be wearing the EEG cap and eye tracking will be measured, However, feedback on EEG and eye tracking measures will not be provided to the participants. 
</comparator>
    <control>Active</control>
    <interventioncode>Treatment: Other</interventioncode>
    <interventioncode>Treatment: Devices</interventioncode>
  </interventions>
  <outcomes>
    <primaryOutcome>
      <outcome>ET behaviour when viewing  emotion stimuli - The remote eye tracker will be used to record eye tracking movements to the eyes, nose, mouth or other areas when viewing the Cambridge Mindreading Face-Voice Battery (CAM) and Movie for the Assessment of Social Cognition (MASC). </outcome>
      <timepoint>Two weeks before intervention, immediately after intervention and 12-weeks follow-up</timepoint>
    </primaryOutcome>
    <primaryOutcome>
      <outcome>Emotion recognition behaviour when viewing emotion stimuli- Emotion recognition accuracy and response time will be measured using the Cambridge Mindreading Face-Voice Battery (CAM) and Movie for the Assessment of Social Cognition (MASC). This is a composite primary outcome to measure emotion recognition behaviour outcomes in a context that is similar to the intervention and whether the skills translate to a context with social interactions within a natural environment. </outcome>
      <timepoint>Two weeks before intervention, immediately after intervention and 12-weeks follow-up</timepoint>
    </primaryOutcome>
    <secondaryOutcome>
      <outcome>Engagement during the intervention measured by drop-out rates </outcome>
      <timepoint>During intervention and immediately after intervention </timepoint>
    </secondaryOutcome>
    <secondaryOutcome>
      <outcome>Self-efficacy in emotion recognition. To assess self-efficacy, the Emotion Recognition Self-Efficacy Questionnaire was designed for this study. This includes questions on the participants level of confidence in emotion recognition outcomes. </outcome>
      <timepoint>Two weeks before intervention, immediately after intervention and 12-weeks follow-up</timepoint>
    </secondaryOutcome>
    <secondaryOutcome>
      <outcome>Quantified EEG (alpha, theta, beta) when viewing emotion stimuli adapted from the Cambridge Mindreading Face-Voice Battery (CAM) </outcome>
      <timepoint>Two weeks before intervention, immediately after intervention and 12-weeks follow-up</timepoint>
    </secondaryOutcome>
    <secondaryOutcome>
      <outcome>Participants' perception on the game- This will be assessed using a questionnaire designed for this study. This questionnaire consists of questions relating to the story, goals, feedback, rewards, levels and choices in the game. </outcome>
      <timepoint>During intervention and immediately after intervention </timepoint>
    </secondaryOutcome>
    <secondaryOutcome>
      <outcome>Screening outcomes- Participants will be undergo screening assessments [Weschler Abbreviated Scale of Intelligence II (WASI-II) and Test of Everyday Attention (TEA)] to screen for intelligence and attention performance, </outcome>
      <timepoint>Pre-intervention (two weeks before the intervention)</timepoint>
    </secondaryOutcome>
  </outcomes>
  <eligibility>
    <inclusivecriteria>Participants will consist of adults with a formal diagnosis of high functioning autism, Asperger syndrome or Pervasive Developmental Disorder Otherwise Not Specified under the Diagnostic Statistical Manual of Mental Disorders IV.</inclusivecriteria>
    <inclusiveminage>18</inclusiveminage>
    <inclusiveminagetype>Years</inclusiveminagetype>
    <inclusivemaxage>60</inclusivemaxage>
    <inclusivemaxagetype>Years</inclusivemaxagetype>
    <inclusivegender>Both males and females</inclusivegender>
    <healthyvolunteer>No</healthyvolunteer>
    <exclusivecriteria>Participants will be excluded if:
1.	They are on a new medication regime for less than three months
2.	Have a history of severe brain injury 
3.	Acute mental health illness  
</exclusivecriteria>
  </eligibility>
  <trial_design>
    <studytype>Interventional</studytype>
    <purpose>Educational / counselling / training</purpose>
    <allocation>Randomised controlled trial</allocation>
    <concealment>The allocation will involve a third party (e.g. a researcher who is not involved in data collection) who holds the allocation schedule and will generate the group allocation. This researcher will be contacted to determine the allocation of the participant. This allocation is only be known to the researchers but will be concealed from the participants. </concealment>
    <sequence>Each participant will be assigned with a number. An online number randomiser (e.g. https://www.randomizer.org/) will be used to determine the group allocation for each participant.</sequence>
    <masking>Blinded (masking used)</masking>
    <assignment>Parallel</assignment>
    <designfeatures />
    <endpoint />
    <statisticalmethods>We will be recruiting approximately 48 adults on the autism spectrum, who will be randomly allocated to two groups. Participants in both groups will be matched based on age, gender, handedness and intelligence quotient (IQ) scores. Based on the analysis of estimations of effect sizes using Cohens d (beta-value of 0.2 and a-value of 0.05), a standardised difference of 0.79 or larger will be detectable with 24 participants in each group. This would ensure that the study is adequately powered to detect a medium (0.79) effect size for all the outcomes. 

Statistical analysis will be conducted to compare the performance between both groups. A Kolmogorov-Smirnov test will be firstly used to determine the distribution of the data. Following to this, univariate analyses using a Mann-Whitney U test or an independent t-test will be used to determine association between the behavioural outcomes (intelligence, attention, autism symptomology and theory of mind) impacting on emotion recognition tasks. Multivariate analyses will then be conducted using modelling to account for the repeated measures contributed by each participant.</statisticalmethods>
    <masking1>True</masking1>
    <masking2>False</masking2>
    <masking3>False</masking3>
    <masking4>False</masking4>
    <patientregistry>False</patientregistry>
    <followup />
    <followuptype />
    <purposeobs />
    <duration />
    <selection />
    <timing />
  </trial_design>
  <recruitment>
    <phase />
    <anticipatedstartdate />
    <actualstartdate>24/08/2016</actualstartdate>
    <anticipatedenddate>24/05/2017</anticipatedenddate>
    <actualenddate />
    <samplesize>48</samplesize>
    <actualsamplesize />
    <recruitmentstatus>Recruiting</recruitmentstatus>
    <anticipatedlastvisitdate>1/12/2017</anticipatedlastvisitdate>
    <actuallastvisitdate />
    <dataanalysis />
    <withdrawnreason />
    <withdrawnreasonother />
    <recruitmentcountry>Australia</recruitmentcountry>
    <recruitmentstate>WA</recruitmentstate>
  </recruitment>
  <sponsorship>
    <primarysponsortype>Individual</primarysponsortype>
    <primarysponsorname>Associate Professor Sonya Girdler</primarysponsorname>
    <primarysponsoraddress>School of Occupational Therapy and Social Work, 
Curtin University, 
Kent St, Bentley WA 6102</primarysponsoraddress>
    <primarysponsorcountry>Australia</primarysponsorcountry>
    <fundingsource>
      <fundingtype>Other</fundingtype>
      <fundingname>Cooperative Research Centre for Living with Autism (Autism CRC)</fundingname>
      <fundingaddress>Level 3 Foxtail Building, Long Pocket
The University of Queensland, Brisbane Qld Australia 4072</fundingaddress>
      <fundingcountry>Australia</fundingcountry>
    </fundingsource>
    <secondarysponsor>
      <sponsortype>Individual</sponsortype>
      <sponsorname>Associate Professor Tele Tan</sponsorname>
      <sponsoraddress>School of Mechanical Engineering, 
Curtin University, 
Kent St, Bentley WA 6102</sponsoraddress>
      <sponsorcountry>Australia</sponsorcountry>
    </secondarysponsor>
    <othercollaborator>
      <othercollaboratortype>Individual</othercollaboratortype>
      <othercollaboratorname>Prof Murray Mayberry</othercollaboratorname>
      <othercollaboratoraddress>School of Psychology,
The University of Western Australia (M304),
35 Stirling Highway
CRAWLEY WA 6009
Australia</othercollaboratoraddress>
      <othercollaboratorcountry>Australia</othercollaboratorcountry>
    </othercollaborator>
    <othercollaborator>
      <othercollaboratortype>Individual</othercollaboratortype>
      <othercollaboratorname>Professor Sven Bolte</othercollaboratorname>
      <othercollaboratoraddress>CAP; Karolinska Institutet/KIND; Gavlegatan 22B, plan 8, 113 30 STOCKHOLM , Sweden</othercollaboratoraddress>
      <othercollaboratorcountry>Sweden</othercollaboratorcountry>
    </othercollaborator>
    <othercollaborator>
      <othercollaboratortype>Individual</othercollaboratortype>
      <othercollaboratorname>Professor Ottmar Lipp</othercollaboratorname>
      <othercollaboratoraddress>School of Psychology and Speech Pathology, 
Curtin University, 
Kent St, Bentley WA 6102</othercollaboratoraddress>
      <othercollaboratorcountry>Australia</othercollaboratorcountry>
    </othercollaborator>
  </sponsorship>
  <ethicsAndSummary>
    <summary>This research project aims to investigate the effectiveness of a computer game integrated with biofeedback to improve emotion recognition skills among adults on the autism spectrum. Biofeedback uses electroencephalography (EEG) and eye tracking to measure brain wave activity and eye gaze patterns. This information will be converted into visual feedback in the computer game. The person is then able to control this feedback to improve their brainwave function and visual search strategies when recognising an emotion.

Participants will be randomly allocated to either the group with biofeedback intervention or a control group without biofeeback intervention. This allocation is only known to the researchers. Each participants will receive approximately 6 hours of intervention over six weeks. 

We expect that the biofeedback intervention will have significant improvements in the following outcomes compared to the control group. 
a) EEG outcomes
b) Eye tracking outcomes
c) Accuracy in emotion recognition skills 
</summary>
    <trialwebsite />
    <publication />
    <ethicsreview>Approved</ethicsreview>
    <publicnotes />
    <ethicscommitee>
      <ethicname>Curtin University Human Research Ethics Committe</ethicname>
      <ethicaddress>Kent Street, Bentley, Perth, Western Australia 6102</ethicaddress>
      <ethicapprovaldate>10/03/2016</ethicapprovaldate>
      <hrec>HR38/2016</hrec>
      <ethicsubmitdate>18/02/2016</ethicsubmitdate>
      <ethiccountry>Australia</ethiccountry>
    </ethicscommitee>
  </ethicsAndSummary>
  <attachment />
  <contacts>
    <contact>
      <title>A/Prof</title>
      <name>Sonya Girdler</name>
      <address>School of Occupational Therapy and Social Work, 
Curtin University, 
Kent Street, Bentley, Perth, Western Australia 6102</address>
      <phone>+61892663630</phone>
      <fax />
      <email>sonya.girdler@curtin.edu.au</email>
      <country>Australia</country>
      <type>Principal Investigator</type>
    </contact>
    <contact>
      <title>A/Prof</title>
      <name>Sonya Girdler</name>
      <address>School of Occupational Therapy and Social Work, 
Curtin University, 
Kent Street, Bentley, Perth, Western Australia 6102</address>
      <phone>+61892663630</phone>
      <fax />
      <email>sonya.girdler@curtin.edu.au</email>
      <country>Australia</country>
      <type>Public Queries</type>
    </contact>
    <contact>
      <title>A/Prof</title>
      <name>Sonya Girdler</name>
      <address>School of Occupational Therapy and Social Work, 
Curtin University, 
Kent Street, Bentley, Perth, Western Australia 6102</address>
      <phone>+61892663630</phone>
      <fax />
      <email>sonya.girdler@curtin.edu.au</email>
      <country>Australia</country>
      <type>Scientific Queries</type>
    </contact>
    <contact>
      <title>A/Prof</title>
      <name>Sonya Girdler</name>
      <address>School of Occupational Therapy and Social Work, 
Curtin University, 
Kent Street, Bentley, Perth, Western Australia 6102</address>
      <phone>+61892663630</phone>
      <fax />
      <email>sonya.girdler@curtin.edu.au</email>
      <country>Australia</country>
      <type>Updating Information</type>
    </contact>
  </contacts>
</ANZCTR_Trial>